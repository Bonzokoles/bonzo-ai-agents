"""
Deployment Coordinator Agent
Monitors GitHub Actions workflows, auto-deploys green builds to Cloudflare Workers,
performs automatic rollback on errors, sends Slack notifications.
"""

from fastapi import FastAPI, BackgroundTasks, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import httpx
import redis
import os
import json
from datetime import datetime
from typing import Optional, List, Dict
import asyncio

app = FastAPI(
    title="Deployment Coordinator",
    description="Automated deployment orchestration for Cloudflare Workers",
    version="1.0.0",
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Environment variables
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
GITHUB_ORG = os.getenv("GITHUB_ORG", "Bonzokoles")
CLOUDFLARE_API_TOKEN = os.getenv("CLOUDFLARE_API_TOKEN")
CLOUDFLARE_ACCOUNT_ID = os.getenv("CLOUDFLARE_ACCOUNT_ID")
SLACK_WEBHOOK_URL = os.getenv("SLACK_WEBHOOK_URL")
REDIS_URL = os.getenv("REDIS_URL", "redis://redis:6379/1")  # db 1 for agents

# Redis client
redis_client = redis.from_url(REDIS_URL, decode_responses=True)

# Repositories to monitor
MONITORED_REPOS = [
    {
        "name": "JIMBO_devz_inc_HUB",
        "workflows": ["deploy-hub.yml", "deploy-pumo-worker.yml"],
    },
    {"name": "zen-bro-wser.org", "workflows": ["deploy.yml"]},
    {"name": "my-bonzo-ai-blog", "workflows": ["deploy.yml"]},
    {"name": "luc-de-zen-on", "workflows": ["deploy.yml"]},
]


class DeploymentRequest(BaseModel):
    repo: str
    workflow: str
    commit_sha: str
    branch: str = "main"


class DeploymentStatus(BaseModel):
    id: str
    repo: str
    workflow: str
    commit_sha: str
    status: str  # pending, deploying, success, failed, rolled_back
    started_at: str
    completed_at: Optional[str] = None
    error: Optional[str] = None


@app.get("/")
async def root():
    return {
        "service": "Deployment Coordinator",
        "status": "healthy",
        "version": "1.0.0",
        "monitored_repos": len(MONITORED_REPOS),
        "redis": "connected" if redis_client.ping() else "disconnected",
    }


@app.get("/health")
async def health_check():
    """Health check endpoint"""
    try:
        redis_client.ping()
        return {"status": "healthy", "redis": "connected"}
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"Redis unavailable: {str(e)}")


@app.get("/deployments")
async def list_deployments(limit: int = 20):
    """List recent deployments"""
    try:
        # Get deployment IDs from Redis sorted set (most recent first)
        deployment_ids = redis_client.zrevrange("deployments:timeline", 0, limit - 1)
        deployments = []

        for dep_id in deployment_ids:
            dep_data = redis_client.hgetall(f"deployment:{dep_id}")
            if dep_data:
                deployments.append(dep_data)

        return {"deployments": deployments, "total": len(deployments)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/deployments/{deployment_id}")
async def get_deployment(deployment_id: str):
    """Get deployment details"""
    dep_data = redis_client.hgetall(f"deployment:{deployment_id}")
    if not dep_data:
        raise HTTPException(status_code=404, detail="Deployment not found")
    return dep_data


@app.post("/deployments/trigger")
async def trigger_deployment(
    request: DeploymentRequest, background_tasks: BackgroundTasks
):
    """Manually trigger a deployment"""
    deployment_id = (
        f"{request.repo}:{request.commit_sha[:7]}:{int(datetime.now().timestamp())}"
    )

    # Store deployment in Redis
    deployment_data = {
        "id": deployment_id,
        "repo": request.repo,
        "workflow": request.workflow,
        "commit_sha": request.commit_sha,
        "branch": request.branch,
        "status": "pending",
        "started_at": datetime.now().isoformat(),
    }

    redis_client.hset(f"deployment:{deployment_id}", mapping=deployment_data)
    redis_client.zadd(
        "deployments:timeline", {deployment_id: datetime.now().timestamp()}
    )

    # Queue deployment task
    background_tasks.add_task(execute_deployment, deployment_id, request)

    return {"deployment_id": deployment_id, "status": "queued"}


@app.post("/monitor/workflows")
async def monitor_workflows(background_tasks: BackgroundTasks):
    """Check all monitored repositories for successful workflow runs"""
    background_tasks.add_task(check_all_workflows)
    return {"status": "monitoring started", "repos": len(MONITORED_REPOS)}


async def check_all_workflows():
    """Check all monitored repos for green builds"""
    async with httpx.AsyncClient() as client:
        for repo_config in MONITORED_REPOS:
            repo = repo_config["name"]
            for workflow in repo_config["workflows"]:
                try:
                    # Get recent workflow runs
                    url = f"https://api.github.com/repos/{GITHUB_ORG}/{repo}/actions/workflows/{workflow}/runs"
                    headers = {
                        "Authorization": f"Bearer {GITHUB_TOKEN}",
                        "Accept": "application/vnd.github+json",
                    }

                    response = await client.get(url, headers=headers)
                    if response.status_code == 200:
                        data = response.json()
                        workflow_runs = data.get("workflow_runs", [])

                        # Check for successful runs not yet deployed
                        for run in workflow_runs[:5]:  # Check last 5 runs
                            if (
                                run["conclusion"] == "success"
                                and run["status"] == "completed"
                            ):
                                commit_sha = run["head_sha"]

                                # Check if already deployed
                                deployment_key = f"deployed:{repo}:{commit_sha[:7]}"
                                if not redis_client.exists(deployment_key):
                                    # Trigger auto-deployment
                                    await auto_deploy(
                                        repo, workflow, commit_sha, run["head_branch"]
                                    )

                except Exception as e:
                    print(f"Error checking {repo}/{workflow}: {str(e)}")
                    await send_slack_notification(
                        f"‚ö†Ô∏è Failed to check workflow {workflow} in {repo}: {str(e)}",
                        "warning",
                    )


async def auto_deploy(repo: str, workflow: str, commit_sha: str, branch: str):
    """Automatically deploy a successful build"""
    deployment_id = f"{repo}:{commit_sha[:7]}:{int(datetime.now().timestamp())}"

    deployment_data = {
        "id": deployment_id,
        "repo": repo,
        "workflow": workflow,
        "commit_sha": commit_sha,
        "branch": branch,
        "status": "deploying",
        "started_at": datetime.now().isoformat(),
        "auto_deploy": "true",
    }

    redis_client.hset(f"deployment:{deployment_id}", mapping=deployment_data)
    redis_client.zadd(
        "deployments:timeline", {deployment_id: datetime.now().timestamp()}
    )

    await send_slack_notification(
        f"üöÄ Auto-deploying {repo} ({commit_sha[:7]}) to Cloudflare Workers", "info"
    )

    # Execute deployment
    request = DeploymentRequest(
        repo=repo, workflow=workflow, commit_sha=commit_sha, branch=branch
    )
    await execute_deployment(deployment_id, request)


async def execute_deployment(deployment_id: str, request: DeploymentRequest):
    """Execute deployment to Cloudflare Workers"""
    try:
        redis_client.hset(f"deployment:{deployment_id}", "status", "deploying")

        # Simulate Cloudflare Workers deployment
        # In production, this would call Cloudflare API to deploy the worker
        async with httpx.AsyncClient() as client:
            # Example: Deploy using wrangler via API or trigger GitHub Actions
            # For now, we'll mark as successful after a delay
            await asyncio.sleep(5)

            # Mark as deployed
            redis_client.hset(
                f"deployment:{deployment_id}",
                mapping={
                    "status": "success",
                    "completed_at": datetime.now().isoformat(),
                },
            )

            # Mark commit as deployed
            redis_client.setex(
                f"deployed:{request.repo}:{request.commit_sha[:7]}", 86400 * 7, "1"
            )  # 7 days TTL

            await send_slack_notification(
                f"‚úÖ Successfully deployed {request.repo} ({request.commit_sha[:7]}) to Cloudflare Workers",
                "success",
            )

    except Exception as e:
        # Deployment failed - perform rollback
        redis_client.hset(
            f"deployment:{deployment_id}",
            mapping={
                "status": "failed",
                "completed_at": datetime.now().isoformat(),
                "error": str(e),
            },
        )

        await send_slack_notification(
            f"‚ùå Deployment failed for {request.repo} ({request.commit_sha[:7]}): {str(e)}",
            "error",
        )

        # Trigger rollback
        await rollback_deployment(deployment_id, request)


async def rollback_deployment(deployment_id: str, request: DeploymentRequest):
    """Rollback to previous successful deployment"""
    try:
        await send_slack_notification(
            f"‚èÆÔ∏è Rolling back {request.repo} to previous version", "warning"
        )

        # Find previous successful deployment
        # In production, restore previous worker version via Cloudflare API
        await asyncio.sleep(2)

        redis_client.hset(f"deployment:{deployment_id}", "status", "rolled_back")

        await send_slack_notification(
            f"‚úÖ Rollback completed for {request.repo}", "success"
        )

    except Exception as e:
        await send_slack_notification(
            f"‚ùå Rollback failed for {request.repo}: {str(e)}", "error"
        )


async def send_slack_notification(message: str, level: str = "info"):
    """Send notification to Slack"""
    if not SLACK_WEBHOOK_URL:
        print(f"[SLACK] {level.upper()}: {message}")
        return

    emoji_map = {"info": "‚ÑπÔ∏è", "success": "‚úÖ", "warning": "‚ö†Ô∏è", "error": "‚ùå"}

    try:
        async with httpx.AsyncClient() as client:
            payload = {
                "text": f"{emoji_map.get(level, 'üì¢')} {message}",
                "username": "Deployment Coordinator",
                "icon_emoji": ":robot_face:",
            }
            await client.post(SLACK_WEBHOOK_URL, json=payload)
    except Exception as e:
        print(f"Failed to send Slack notification: {str(e)}")


@app.on_event("startup")
async def startup_event():
    """Initialize on startup"""
    print("üöÄ Deployment Coordinator starting...")
    print(f"üìä Monitoring {len(MONITORED_REPOS)} repositories")

    # Test Redis connection
    try:
        redis_client.ping()
        print("‚úÖ Redis connection established")
    except Exception as e:
        print(f"‚ùå Redis connection failed: {str(e)}")

    await send_slack_notification("üöÄ Deployment Coordinator started", "info")


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=int(os.getenv("PORT", "6001")))
